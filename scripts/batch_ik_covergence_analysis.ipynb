{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c28e1d0",
   "metadata": {},
   "source": [
    "# Batch IK convergence analysis\n",
    "This notebook analysis the emprirical convergence properties of the two batch ik methods - the jacobian psuedo inverse method and the auto-diff method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25de89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from typing import Callable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jrl.utils import to_torch, set_seed\n",
    "from jrl.robot import Robot\n",
    "from jrl.robots import Panda\n",
    "from jrl.conversions import geodesic_distance_between_quaternions\n",
    "from jrl.evaluation import solution_pose_errors\n",
    "\n",
    "set_seed(0)\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04759263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_mean_std(fn: Callable, k: int):\n",
    "    runtimes = []\n",
    "    for _ in range(k):\n",
    "        t0 = time()\n",
    "        fn()\n",
    "        runtimes.append(1000 * (time() - t0))\n",
    "    return np.mean(runtimes), np.std(runtimes)\n",
    "\n",
    "@dataclass\n",
    "class OptimStepEval:\n",
    "    name: str\n",
    "    mean_t_err: float\n",
    "    mean_R_err: float\n",
    "    t_err_std: float\n",
    "    R_err_std: float\n",
    "    alpha: float\n",
    "    t_elapsed: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Panda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def klampt\n",
    "\n",
    "methods = {\n",
    "    # \"Klampt invJac cpu\": lambda: robot.inverse_kinematics_single_step_batch_pt(goalposes_cpu, x_pt_cpu),\n",
    "    \"jac-pinv (J from klampt)\": lambda x, target, alpha: robot.inverse_kinematics_single_step_batch_pt(target, x, alpha=alpha),\n",
    "    \"jac-pinv (J from klampt)\": lambda x, target, alpha: robot.inverse_kinematics_single_step_batch_pt(target, x, alpha=alpha),\n",
    "    \"AutoDiff\": lambda x, target, alpha: robot.inverse_kinematics_autodiff_single_step_batch_pt(target, x, alpha=alpha),\n",
    "    \"Levenburg-Marquardt\": lambda x, target, alpha: robot.inverse_kinematics_single_step_levenburg_marquardt(target, x),\n",
    "}\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "goalpose_angles, goalposes = robot.sample_joint_angles_and_poses(batch_size)\n",
    "goalposes_cuda = to_torch(goalposes.copy(), device=\"cuda\")\n",
    "# x_pt, _ = robot.sample_joint_angles_and_poses(batch_size) # randomly drawn\n",
    "# x_pt = to_torch(x_pt).cuda()\n",
    "x_pt = to_torch(goalpose_angles.copy()).cuda() # close to solution\n",
    "x_pt = robot.clamp_to_joint_limits(x_pt + torch.randn_like(x_pt) / 10)\n",
    "    \n",
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"method\", \n",
    "        \"alpha\", \n",
    "        \"number of solutions\", \n",
    "        \"total runtime (s)\", \n",
    "        \"number of optimization steps\", \n",
    "        \"final mean translational error (cm)\", \n",
    "        \"final mean rotational error (deg)\"\n",
    "    ])\n",
    "\n",
    "all_loss_histories = []\n",
    "for name, method in methods.items():\n",
    "    \n",
    "#     for alpha in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "#     for alpha in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    for alpha in [0.2]:\n",
    "        \n",
    "        loss_history = []\n",
    "        x_pt_i = x_pt.detach()\n",
    "\n",
    "        t_elapsed = 0\n",
    "        counter = 0\n",
    "\n",
    "        while (len(loss_history) == 0 or loss_history[-1].mean_t_err > 0.1) and counter < 200:\n",
    "            l2_errors, ang_errors = solution_pose_errors(robot, x_pt_i, goalposes_cuda)\n",
    "            l2_errors = 100 * l2_errors\n",
    "            ang_errors = np.rad2deg(ang_errors)\n",
    "\n",
    "            loss_history.append(\n",
    "                OptimStepEval(\n",
    "                    name=name,\n",
    "                    mean_t_err=l2_errors.mean().item(),\n",
    "                    mean_R_err=ang_errors.mean().item(),\n",
    "                    t_err_std=l2_errors.mean().item(),\n",
    "                    R_err_std=ang_errors.mean().item(),\n",
    "                    alpha=alpha,\n",
    "                    t_elapsed=t_elapsed))\n",
    "\n",
    "            t0i = time()\n",
    "            x_pt_i = method(x_pt_i, goalposes_cuda, alpha)\n",
    "            t_elapsed += time() - t0i\n",
    "            counter += 1 \n",
    "            \n",
    "        new_row = [name, alpha, batch_size, t_elapsed, counter, loss_history[-1].mean_t_err, loss_history[-1].mean_R_err]\n",
    "        df.loc[len(df)] = new_row\n",
    "        all_loss_histories.append(loss_history)\n",
    "        \n",
    "        if \"Levenburg\" in name: \n",
    "            break\n",
    "\n",
    "        \n",
    "df = df.sort_values(by=[\"method\", \"alpha\"])\n",
    "df_success = df[df['final mean translational error (cm)'] < 0.1]\n",
    "df_success.sort_values(by=[\"total runtime (s)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle(f\"IK convergence of configs close to solutions - batch_size={batch_size}\")\n",
    "\n",
    "TARGET_t_err = 0.1\n",
    "max_n_steps_plotted = 60\n",
    "\n",
    "\n",
    "for loss_history in all_loss_histories:\n",
    "    tsteps = np.arange(len(loss_history))    \n",
    "    telapsed = np.array([ose.t_elapsed for ose in loss_history])\n",
    "    mean_ts = np.array([ose.mean_t_err for ose in loss_history])\n",
    "    std_ts = np.array([ose.t_err_std for ose in loss_history])\n",
    "    \n",
    "    if len(loss_history) >= max_n_steps_plotted:\n",
    "        tsteps = tsteps[0:max_n_steps_plotted]\n",
    "        telapsed = telapsed[0:max_n_steps_plotted]\n",
    "        mean_ts = mean_ts[0:max_n_steps_plotted]\n",
    "        std_ts = std_ts[0:max_n_steps_plotted]\n",
    "        \n",
    "    label = f\"{loss_history[0].name}, alpha={loss_history[0].alpha}\"\n",
    "\n",
    "    axs[0].plot(tsteps, TARGET_t_err*np.ones(tsteps.size), color=\"green\", linestyle=\"dotted\")\n",
    "    axs[1].plot(telapsed, TARGET_t_err*np.ones(tsteps.size), color=\"green\", linestyle=\"dotted\")\n",
    "    \n",
    "    if mean_ts[-1] < TARGET_t_err:\n",
    "        axs[0].plot(tsteps, mean_ts, label=label)\n",
    "        axs[1].plot(telapsed, mean_ts, label=label)\n",
    "    else:\n",
    "        axs[0].plot(tsteps, mean_ts, color=\"red\", alpha=0.15, label=label)\n",
    "        axs[1].plot(telapsed, mean_ts, color=\"red\", alpha=0.15, label=label)\n",
    "    \n",
    "for ax in axs:\n",
    "    ax.set_ylabel(\"Mean translational error (cm)\")\n",
    "    ax.set_ylim(0, 10)\n",
    "\n",
    "axs[1].legend()\n",
    "axs[0].set_xlabel(\"Steps\")\n",
    "axs[1].set_xlabel(\"Runtime (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a42e76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fc189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
